{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/cocoza4/workspace/absorouteio/asr-face-recognition/src')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "from models import create_model\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 10\n",
    "n_classes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<models.ArcFaceModel at 0x7f5e7c305a58>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model('seresnet152', emb_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 112, 112, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open('/home/cocoza4/datasets/asr_plastic/train/IMG_20200222_011937.jpg').resize((112, 112))\n",
    "img = np.asarray(img).astype('float32') / 255.\n",
    "inputs = np.array([img, img])\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[-0.0036821 , -0.02201095, -0.01564291,  0.00357328, -0.01834397,\n",
       "        -0.00714342,  0.00014136, -0.0334766 ,  0.03271113,  0.03801651],\n",
       "       [-0.00368211, -0.02201094, -0.0156429 ,  0.0035733 , -0.01834397,\n",
       "        -0.00714341,  0.00014138, -0.0334766 ,  0.03271111,  0.03801651]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [3, 13, 30, 3]\n",
    "filter_list = [64, 64, 128, 256, 512]\n",
    "bottle_neck = False\n",
    "num_stages = 4\n",
    "\n",
    "\n",
    "version_se = net_se = 0\n",
    "net_act = 'prelu'\n",
    "version_input = net_input = 1\n",
    "net_unit = 1\n",
    "version_unit = 3\n",
    "fc_type = 'E'\n",
    "num_unit = len(units)\n",
    "dim_match = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "\n",
    "def mx_execute(symbol, tensors):\n",
    "    shapes = {n: t.shape for n, t in tensors.items()}\n",
    "    executor = symbol.simple_bind(ctx=mx.cpu(), **shapes)\n",
    "    return executor.forward(**tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 200, 200)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = np.random.normal(size=(2, 3, 200, 200)).astype('float32')\n",
    "tf_inp = np.transpose(inp, (0, 3, 2, 1))\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590.8825, 590.8825)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.sum(), tf_inp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_inp = nd.from_numpy(inp)\n",
    "mx_inp.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 200, 200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_inp.asnumpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Symbol pool>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx = mx.sym.Variable('embedding')\n",
    "pool = mx.sym.Pooling(data=xxx, global_pool=True, kernel=(7, 7), pool_type='avg', name='pool')\n",
    "pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " [[[[-0.00708314]]\n",
       " \n",
       "   [[-0.00617472]]\n",
       " \n",
       "   [[ 0.00464411]]]\n",
       " \n",
       " \n",
       "  [[[ 0.0024788 ]]\n",
       " \n",
       "   [[ 0.0151381 ]]\n",
       " \n",
       "   [[ 0.00024123]]]]\n",
       " <NDArray 2x3x1x1 @cpu(0)>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_execute(pool, tensors={'embedding': mx_inp.asnumpy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "MeanLayer = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=[1, 2], keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 1, 3), dtype=float32, numpy=\n",
       "array([[[[-0.00708316, -0.00617473,  0.00464414]]],\n",
       "\n",
       "\n",
       "       [[[ 0.0024788 ,  0.01513811,  0.00024121]]]], dtype=float32)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MeanLayer(tf_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[-0.00708316, -0.00617473,  0.00464414],\n",
       "       [ 0.0024788 ,  0.01513811,  0.00024121]], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.GlobalAveragePooling2D()(tf_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filter = 64\n",
    "stride = strides = (2, 2)\n",
    "\n",
    "def Conv(**kwargs):\n",
    "    body = mx.sym.Convolution(**kwargs)\n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mx.sym.Variable('data')\n",
    "bn1 = mx.sym.BatchNorm(data=data, fix_gamma=False, eps=2e-5,)\n",
    "conv1 = Conv(data=bn1, num_filter=num_filter, kernel=(3,3), stride=(1,1), pad=(1,1),\n",
    "                              no_bias=True)\n",
    "bn2 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, eps=2e-5)\n",
    "# act1 = Act(data=bn2, act_type=act_type, name=name + '_relu1')\n",
    "act1 = mx.sym.LeakyReLU(data=bn2, act_type='prelu')\n",
    "conv2 = Conv(data=act1, num_filter=num_filter, kernel=(3,3), stride=stride, pad=(1,1),\n",
    "                              no_bias=True)\n",
    "bn3 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, eps=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64, 100, 100)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_execute(bn3, tensors={'data': mx_inp.asnumpy()})[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'xxx'\n",
    "bn1 = BatchNormalization(name=name + '_bn1')\n",
    "conv1 = Conv2D(num_filter, kernel_size=(3, 3), strides=(1, 1), padding='valid', \n",
    "                            use_bias=False, name=name + '_conv1')\n",
    "bn2 = BatchNormalization(name=name + '_bn2')\n",
    "prelu1 = PReLU(name=name + 'act1')\n",
    "conv2 = Conv2D(num_filter, kernel_size=(3, 3), strides=stride, padding='valid',\n",
    "                                                                         use_bias=False, name=name + '_conv2')\n",
    "bn3 = BatchNormalization(name=name + '_bn3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 100, 100, 64])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_inp = tf_inp.astype('float32')\n",
    "x = bn1(tf_inp)\n",
    "x = ZeroPadding2D((1, 1))(x)\n",
    "x = conv1(x)\n",
    "x = bn2(x)\n",
    "x = prelu1(x)\n",
    "x = ZeroPadding2D((1, 1))(x)\n",
    "x = conv2(x)\n",
    "x = bn3(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = mx.sym.BatchNorm(data=data, fix_gamma=False, eps=2e-5, name=name + '_bn1')\n",
    "conv1 = Conv(data=bn1, num_filter=num_filter, kernel=(3,3), stride=(1,1), pad=(1,1),\n",
    "                              no_bias=True, name=name + '_conv1')\n",
    "bn2 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, eps=2e-5, name=name + '_bn2')\n",
    "# act1 = Act(data=bn2, act_type=act_type, name=name + '_relu1')\n",
    "act1 = mx.sym.LeakyReLU(data=bn2, act_type='prelu')\n",
    "conv2 = Conv(data=act1, num_filter=num_filter, kernel=(3,3), stride=stride, pad=(1,1),\n",
    "                              no_bias=True, name=name + '_conv2')\n",
    "bn3 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, eps=2e-5,  name=name + '_bn3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64, 100, 100)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_execute(bn3, tensors={'data': mx_inp.asnumpy()})[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1sc = Conv(data=data, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n",
    "                                name=name+'_conv1sc')\n",
    "shortcut = mx.sym.BatchNorm(data=conv1sc, fix_gamma=False, eps=2e-5, name=name + '_sc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64, 100, 100)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_execute(bn3, tensors={'data': mx_inp.asnumpy()})[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_sc = Conv2D(num_filter, kernel_size=(1, 1), strides=strides, padding='valid',\n",
    "                                   use_bias=False, name=name + '_conv1sc')\n",
    "bn_sc = BatchNormalization(name=name + '_sc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 100, 100, 64])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = conv1_sc(tf_inp)\n",
    "x = bn_sc(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_pool = AveragePooling2D(name=name + '_se_pooling')\n",
    "        \n",
    "se_conv1 = Conv2D(num_filter//16, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "                       use_bias=True, name=name + '_se_conv1')\n",
    "se_prelu = PReLU(name=name + '_se_act1')\n",
    "se_conv2 = Conv2D(num_filter, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "                       use_bias=True, name=name + '_se_conv2')\n",
    "se_sigmoid = Activation('sigmoid', name=name + '_se_sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 1, 1, 64])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = se_pool(tf_inp)\n",
    "x = se_conv1(x)\n",
    "x = se_prelu(x)\n",
    "x = se_conv2(x)\n",
    "x = se_sigmoid(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1sc = Conv(data=data, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True)\n",
    "shortcut = mx.sym.BatchNorm(data=conv1sc, fix_gamma=False, eps=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64, 100, 100)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_execute(shortcut, tensors={'data': mx_inp.asnumpy()})[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_conv = tf.keras.layers.Conv2D(num_filter, kernel_size=(1, 1), \n",
    "                                 strides=stride, padding='same', use_bias=False)\n",
    "tf_result = tf_conv(tf_inp).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100, 100, 64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 200, 200)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = bn3 + shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64, 100, 100)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_execute(out, tensors={'data': mx_inp.asnumpy()})[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 300, 400)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_file = '/home/cocoza4/datasets/asr_plastic_400_400/IMG_20200222_011937.jpg'\n",
    "img = mx.image.imread(img_file)\n",
    "img = img.transpose((2,0,1))  # Transposing from (224, 224, 3) to (3, 224, 224)\n",
    "img = img.expand_dims(axis=0).astype('float') # change the shape from (3, 224, 224) to (1, 3, 224, 224)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 3, 3, 3), (3, 3, 3, 5))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.random.normal(size=(5, 3, 3, 3))\n",
    "tf_weights = np.transpose(weights, (1, 2, 3, 0))\n",
    "weights.shape, tf_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Symbol conv>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = mx.sym.Variable('embedding')\n",
    "conv = mx.symbol.Convolution(data=a, num_filter=5, kernel=(3, 3), stride=(1,1), \n",
    "                             pad=(1, 1), name='conv', no_bias=True)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 300, 400)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_result = mx_execute(conv, tensors={'embedding': img, 'conv_weight': weights})[0].asnumpy()\n",
    "mx_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mx_residual_bock(data, num_filter, stride, name, dim_match=False):\n",
    "    bn1 = mx.sym.BatchNorm(data=data, fix_gamma=False, eps=2e-5, name=name + '_bn1')\n",
    "    conv1 = Conv(data=bn1, num_filter=num_filter, kernel=(3,3), stride=(1,1), pad=(1,1),\n",
    "                                  no_bias=True, name=name + '_conv1')\n",
    "    bn2 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, eps=2e-5, name=name + '_bn2')\n",
    "#     act1 = Act(data=bn2, act_type=act_type, name=name + '_relu1')\n",
    "    act1 = mx.sym.LeakyReLU(data=bn2, act_type='prelu')\n",
    "    conv2 = Conv(data=act1, num_filter=num_filter, kernel=(3,3), stride=stride, pad=(1,1),\n",
    "                                  no_bias=True, name=name + '_conv2')\n",
    "    bn3 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, eps=2e-5, name=name + '_bn3')\n",
    "    \n",
    "    #se begin\n",
    "    body = mx.sym.Pooling(data=bn3, global_pool=True, kernel=(7, 7), pool_type='avg', name=name+'_se_pool1')\n",
    "    body = Conv(data=body, num_filter=num_filter//16, kernel=(1,1), stride=(1,1), pad=(0,0),\n",
    "                            name=name+\"_se_conv1\")\n",
    "#     body = Act(data=body, act_type=act_type, name=name+'_se_relu1')\n",
    "    body = mx.sym.LeakyReLU(data=body, act_type='prelu')\n",
    "    body = Conv(data=body, num_filter=num_filter, kernel=(1,1), stride=(1,1), pad=(0,0),\n",
    "                            name=name+\"_se_conv2\")\n",
    "    body = mx.symbol.Activation(data=body, act_type='sigmoid', name=name+\"_se_sigmoid\")\n",
    "    bn3 = mx.symbol.broadcast_mul(bn3, body)\n",
    "    #se end\n",
    "\n",
    "    if dim_match:\n",
    "        shortcut = data\n",
    "    else:\n",
    "        conv1sc = Conv(data=data, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n",
    "                                        name=name+'_conv1sc')\n",
    "        shortcut = mx.sym.BatchNorm(data=conv1sc, fix_gamma=False, eps=2e-5, name=name + '_sc')\n",
    "    \n",
    "    return bn3 + shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64, 100, 100)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mx.sym.Variable('data')\n",
    "v = mx_residual_bock(data, num_filter, (2, 2), 'xxx', dim_match=False)\n",
    "mx_result = mx_execute(v, tensors={'data': mx_inp.asnumpy()})[0]\n",
    "mx_result.asnumpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64, 100, 100)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mx.sym.Variable('data')\n",
    "v = mx_residual_bock(data, num_filter, (1, 1), 'xxx', dim_match=True)\n",
    "mx_result = mx_execute(v, tensors={'data': mx_result.asnumpy()})[0].asnumpy()\n",
    "mx_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data (2, 64, 100, 100)\n",
      "data (2, 64, 100, 100)\n",
      "data (2, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 10)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = mx.sym.Variable('data')\n",
    "# v = mx_residual_bock(data, num_filter, stride, 'xxx')\n",
    "\n",
    "# body = mx_execute(v, tensors={'data': mx_inp.asnumpy()})[0].asnumpy()\n",
    "data = mx.sym.Variable('data')\n",
    "\n",
    "body = mx.sym.BatchNorm(data=data, fix_gamma=False, eps=2e-5, name='bn1')\n",
    "print('data', mx_execute(body, tensors={'data': mx_result})[0].asnumpy().shape)\n",
    "\n",
    "body = mx.symbol.Dropout(data=body, p=0.4)\n",
    "print('data', mx_execute(body, tensors={'data': mx_result})[0].asnumpy().shape)\n",
    "fc1 = mx.sym.FullyConnected(data=body, num_hidden=10, name='pre_fc1')\n",
    "print('data', mx_execute(fc1, tensors={'data': mx_result})[0].asnumpy().shape) # mxnet altomatically reshapes\n",
    "fc1 = mx.sym.BatchNorm(data=fc1, fix_gamma=True, eps=2e-5, name='fc1')\n",
    "\n",
    "xxx = mx_execute(fc1, tensors={'data': mx_result})[0].asnumpy()\n",
    "xxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300, 400, 3)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_img = np.asarray(Image.open(img_file))\n",
    "tf_img = np.expand_dims(tf_img, axis=0).astype('float32')\n",
    "tf_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0318 00:05:57.249577 140668921968448 base_layer.py:1790] Layer conv2d_23 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 298, 398, 5)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_conv = tf.keras.layers.Conv2D(5,  weights=[tf_weights], kernel_size=(3, 3), \n",
    "                                 strides=(1, 1), padding='valid', use_bias=False)\n",
    "tf_result = tf_conv(tf_img).numpy()\n",
    "tf_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(np.transpose(tf_result, (0, 3, 1, 2)), mx_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = mx.sym.BatchNorm(data=data, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + '_bn1')\n",
    "conv1 = Conv(data=bn1, num_filter=num_filter, kernel=(3,3), stride=(1,1), pad=(1,1),\n",
    "                              no_bias=True, workspace=workspace, name=name + '_conv1')\n",
    "bn2 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + '_bn2')\n",
    "act1 = Act(data=bn2, act_type=act_type, name=name + '_relu1')\n",
    "conv2 = Conv(data=act1, num_filter=num_filter, kernel=(3,3), stride=stride, pad=(1,1),\n",
    "                              no_bias=True, workspace=workspace, name=name + '_conv2')\n",
    "bn3 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + '_bn3')\n",
    "if use_se:\n",
    "  #se begin\n",
    "  body = mx.sym.Pooling(data=bn3, global_pool=True, kernel=(7, 7), pool_type='avg', name=name+'_se_pool1')\n",
    "  body = Conv(data=body, num_filter=num_filter//16, kernel=(1,1), stride=(1,1), pad=(0,0),\n",
    "                            name=name+\"_se_conv1\", workspace=workspace)\n",
    "  body = Act(data=body, act_type=act_type, name=name+'_se_relu1')\n",
    "  body = Conv(data=body, num_filter=num_filter, kernel=(1,1), stride=(1,1), pad=(0,0),\n",
    "                            name=name+\"_se_conv2\", workspace=workspace)\n",
    "  body = mx.symbol.Activation(data=body, act_type='sigmoid', name=name+\"_se_sigmoid\")\n",
    "  bn3 = mx.symbol.broadcast_mul(bn3, body)\n",
    "  #se end\n",
    "\n",
    "if dim_match:\n",
    "    shortcut = data\n",
    "else:\n",
    "    conv1sc = Conv(data=data, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n",
    "                                    workspace=workspace, name=name+'_conv1sc')\n",
    "    shortcut = mx.sym.BatchNorm(data=conv1sc, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + '_sc')\n",
    "if memonger:\n",
    "    shortcut._set_attr(mirror_stage='True')\n",
    "return bn3 + shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2D = tf.keras.layers.Conv2D\n",
    "BatchNormalization = tf.keras.layers.BatchNormalization\n",
    "PReLU = tf.keras.layers.PReLU\n",
    "Activation = tf.keras.layers.Activation\n",
    "ZeroPadding2D = tf.keras.layers.ZeroPadding2D\n",
    "Dense = tf.keras.layers.Dense\n",
    "Reshape = tf.keras.layers.Reshape\n",
    "Flatten = tf.keras.layers.Flatten\n",
    "GlobalAveragePooling2D = tf.keras.layers.GlobalAveragePooling2D\n",
    "\n",
    "# AveragePooling2D = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=[1, 2], keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragePooling2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def call(self, x):\n",
    "        return tf.reduce_mean(x, axis=[1, 2], keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 112, 112, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open('/home/cocoza4/datasets/asr_plastic/train/IMG_20200222_011937.jpg').resize((112, 112))\n",
    "img = np.asarray(img).astype('float32') / 255.\n",
    "inputs = np.array([img, img])\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, filters, strides, name, shortcut=True):\n",
    "        super().__init__()\n",
    "        self.bn1 = BatchNormalization(name=name + '_bn1')\n",
    "        self.conv1 = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='valid', \n",
    "                            use_bias=False, name=name + '_conv1')\n",
    "        self.bn2 = BatchNormalization(name=name + '_bn2')\n",
    "        self.prelu1 = PReLU(name=name + 'act1')\n",
    "        self.conv2 = Conv2D(filters, kernel_size=(3, 3), strides=strides, padding='valid',\n",
    "                            use_bias=False, name=name + '_conv2')\n",
    "        self.bn3 = BatchNormalization(name=name + '_bn3')\n",
    "        \n",
    "        self.se_pool = AveragePooling2D(name=name + '_se_pooling')\n",
    "        \n",
    "        self.se_conv1 = Conv2D(filters//16, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "                               use_bias=True, name=name + '_se_conv1')\n",
    "        self.se_prelu = PReLU(name=name + '_se_act1')\n",
    "        self.se_conv2 = Conv2D(filters, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "                               use_bias=True, name=name + '_se_conv2')\n",
    "        self.se_sigmoid = Activation('sigmoid', name=name + '_se_sigmoid')\n",
    "\n",
    "        self.shortcut = shortcut\n",
    "        if shortcut:\n",
    "            self.conv1_sc = Conv2D(filters, kernel_size=(1, 1), strides=strides, padding='valid',\n",
    "                                   use_bias=False, name=name + '_conv1sc')\n",
    "            self.bn_sc = BatchNormalization(name=name + '_sc')\n",
    "        \n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        # Residual Block\n",
    "        x = self.bn1(inputs, training=training)\n",
    "        x = ZeroPadding2D((1, 1))(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = self.prelu1(x)\n",
    "        x = ZeroPadding2D((1, 1))(x)\n",
    "        x = self.conv2(x)\n",
    "        bn3 = self.bn3(x, training=training)\n",
    "        \n",
    "        # SE\n",
    "        x = self.se_pool(bn3)\n",
    "        x = self.se_conv1(x)\n",
    "        x = self.se_prelu(x)\n",
    "        x = self.se_conv2(x)\n",
    "        x = self.se_sigmoid(x)\n",
    "        bn3 = tf.keras.layers.multiply([bn3, x])\n",
    "        \n",
    "        if self.shortcut:\n",
    "            shortcut = self.bn_sc(self.conv1_sc(inputs))\n",
    "        else:\n",
    "            shortcut = inputs\n",
    "        \n",
    "        return bn3 + shortcut\n",
    "        \n",
    "        \n",
    "class StackedBlock():\n",
    "    \n",
    "    def __init__(self, filters, blocks, strides, name):\n",
    "        self.blocks = []\n",
    "        self.block = ResidualBlock(filters, strides=strides, name=name, shortcut=True)\n",
    "        for i in range(blocks):\n",
    "            block = ResidualBlock(filters, strides=(1, 1), name=name+f'_block{i+1}', shortcut=False)\n",
    "            self.blocks.append(block)\n",
    "    \n",
    "    def __call__(self, x, training=False):\n",
    "        x = self.block(x, training=training)\n",
    "        for block in self.blocks:\n",
    "            x = block(x, training=training)\n",
    "        return x\n",
    "    \n",
    "                \n",
    "        \n",
    "class ResNet100(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, filters, blocks, embedding_size=512, name='resnet100'):\n",
    "        super().__init__()\n",
    "        assert len(filters) == len(blocks)\n",
    "        \n",
    "        self.pad = ZeroPadding2D((1, 1), name='pad')\n",
    "        self.conv1 = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), \n",
    "                            padding='valid', use_bias=False, name='conv1')\n",
    "        self.bn1 = BatchNormalization(name='conv1_bn')\n",
    "        self.prelu1 = PReLU(name='conv1_relu')\n",
    "        \n",
    "        self.stacks = []\n",
    "        for i, f in enumerate(filters):\n",
    "            name = f'conv{i+1}'\n",
    "            stack = StackedBlock(f, blocks=blocks[i], strides=(2, 2), name=name)\n",
    "            self.stacks.append(stack)\n",
    "            \n",
    "        self.bnx = BatchNormalization()\n",
    "        # self.dropout = tf.keras.layers.Dropout(0.4)\n",
    "        self.flatten = Flatten()\n",
    "        self.dense = Dense(embedding_size, use_bias=False)\n",
    "        \n",
    "        self.bny = BatchNormalization(scale=False)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.pad(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.prelu1(x)\n",
    "        \n",
    "        for stack in self.stacks:\n",
    "            x = stack(x)\n",
    "        \n",
    "        print(x.shape)\n",
    "        x = self.bnx(x, training=training)\n",
    "        print(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.bny(x, training=training)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, kernel_size, filters, name='conv'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = Conv2D(filters[0], kernel_size=(1, 1), strides=(1, 1), \n",
    "                            padding='valid', use_bias=False, name=name+'_conv1')\n",
    "        self.bn1 = BatchNormalization(name=name+'_bn1')\n",
    "        self.relu1 = Activation('relu', name=name+'_relu1')\n",
    "        \n",
    "        self.conv2 = Conv2D(filters[1], kernel_size=kernel_size, # strides=strides, \n",
    "                            padding='same', use_bias=False, name=name+'_conv2')\n",
    "        self.bn2 = BatchNormalization(name=name+'_bn2')\n",
    "        self.relu2 = Activation('relu', name=name+'_relu2')\n",
    "        \n",
    "        self.conv3 = Conv2D(filters[2], kernel_size=(1, 1), strides=(1, 1), \n",
    "                            padding='valid', use_bias=False, name=name+'_conv3')\n",
    "        self.bn3 = BatchNormalization(name=name+'_bn3')\n",
    "        \n",
    "        self.se_block = SEBlock(filters[2], name=name)\n",
    "        \n",
    "        self.relu3 = Activation('relu', name=name+'_relu3')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(inputs)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x, training=training)\n",
    "        \n",
    "        x = self.se_block(x, training=training)\n",
    "        \n",
    "        x = tf.keras.layers.add([x, inputs])\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "        super().__init__()\n",
    "        \n",
    "        block_name = str(stage) + \"_\" + str(block)\n",
    "        name = 'conv' + block_name\n",
    "        \n",
    "        self.conv1 = Conv2D(filters, kernel_size=(1, 1), strides=(1, 1), \n",
    "                            padding='valid', use_bias=False, name=name+'_conv1')\n",
    "        self.bn1 = BatchNormalization(name=name+'_bn1')\n",
    "        self.relu1 = Activation('relu', name=name+'_relu1')\n",
    "        \n",
    "        self.conv2 = Conv2D(filters[1], kernel_size=kernel_size, strides=strides, \n",
    "                            padding='same', use_bias=False, name=name+'_conv2')\n",
    "        self.bn2 = BatchNormalization(name=name+'_bn2')\n",
    "        self.relu2 = Activation('relu', name=name+'_relu2')\n",
    "        \n",
    "        self.conv3 = Conv2D(filters[2], kernel_size=(1, 1), strides=(1, 1), \n",
    "                            padding='valid', use_bias=False, name=name+'_conv3')\n",
    "        self.bn3 = BatchNormalization(name=name+'_bn3')\n",
    "        \n",
    "        self.se_block = SEBlock(filters[2], name=name)\n",
    "        \n",
    "        self.conv4 = Conv2D(filters[2], kernel_size=(1, 1), strides=strides, \n",
    "                            padding='valid', use_bias=False, name=name+'_conv4')\n",
    "        self.bn4 = BatchNormalization(name=name+'_bn4')\n",
    "        self.relu4 = Activation('relu', name=name+'_relu4')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(inputs)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x, training=training)\n",
    "        \n",
    "        x = self.se_block(x, training=training)\n",
    "        \n",
    "        shortcut = self.conv4(x)\n",
    "        shortcut = self.bn4(shortcut, training=training)\n",
    "        \n",
    "        x = tf.keras.layers.add([x, shortcut])\n",
    "        x = self.relu4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class Bottleneck(tf.keras.Model):\n",
    "    \n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, filters, stage, block, strides=1, downsample=None):\n",
    "        super().__init__()\n",
    "        block_name = str(stage) + \"_\" + str(block)\n",
    "        name = 'conv' + block_name\n",
    "        \n",
    "        self.conv1 = Conv2D(filters, kernel_size=1, strides=1, \n",
    "                            use_bias=False, name=name+'_conv1')\n",
    "        self.bn1 = BatchNormalization(name=name+'_bn1')\n",
    "        self.relu1 = Activation('relu', name=name+'_relu1')\n",
    "        \n",
    "        self.conv2 = Conv2D(filters, kernel_size=3, strides=strides, \n",
    "                            padding='same', use_bias=False, name=name+'_conv2')\n",
    "        self.bn2 = BatchNormalization(name=name+'_bn2')\n",
    "        self.relu2 = Activation('relu', name=name+'_relu2')\n",
    "        \n",
    "        self.conv3 = Conv2D(filters * self.expansion, kernel_size=1, strides=1, \n",
    "                            use_bias=False, name=name+'_conv3')\n",
    "        self.bn3 = BatchNormalization(name=name+'_bn3')\n",
    "        self.se_block = SEBlock(filters * self.expansion, name=name)\n",
    "        self.relu3 = Activation('relu', name=name+'_relu3')\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(inputs, training=training)\n",
    "        else:\n",
    "            identity = inputs\n",
    "        \n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x, training=training)\n",
    "        \n",
    "        x = self.se_block(x, training=training)\n",
    "        \n",
    "        x = tf.keras.layers.add([x, identity])\n",
    "        \n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class BasicBlock(tf.keras.Model):\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, filters, stage, block, strides=1, downsample=None):\n",
    "        super().__init__()\n",
    "        block_name = str(stage) + \"_\" + str(block)\n",
    "        name = 'conv' + block_name\n",
    "        \n",
    "        self.conv1 = Conv2D(filters, kernel_size=3, strides=strides, \n",
    "                            padding='same', use_bias=False, name=name+'_conv1')\n",
    "        self.bn1 = BatchNormalization(name=name+'_bn1')\n",
    "        self.relu1 = Activation('relu', name=name+'_relu1')\n",
    "        \n",
    "        self.conv2 = Conv2D(filters, kernel_size=3, strides=1, \n",
    "                            padding='same', use_bias=False, name=name+'_conv2')\n",
    "        self.bn2 = BatchNormalization(name=name+'_bn2')\n",
    "        self.relu2 = Activation('relu', name=name+'_relu2')\n",
    "        self.se_block = SEBlock(filters, name=name)\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(inputs, training=training)\n",
    "        else:\n",
    "            identity = inputs\n",
    "        \n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = self.se_block(x, training=training)\n",
    "        \n",
    "        x = tf.keras.layers.add([x, identity])\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "class SEBlock(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, filters, name='conv'):\n",
    "        super().__init__()\n",
    "#         self.se_pool = GlobalAveragePooling2D(name=name+'_se_pool')\n",
    "#         self.se_dense1 = Dense(filters // 16, activation='relu', name=name+'_se_fc1') # squeeze\n",
    "#         self.se_dense2 = Dense(filters, activation='sigmoid', name=name+'_se_fc2') # excite\n",
    "        self.pool = AveragePooling2D(name=name+'_se_pooling')\n",
    "        \n",
    "        self.conv1 = Conv2D(filters//16, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "                               use_bias=True, name=name + '_se_conv1')\n",
    "        self.relu1 = Activation('relu', name=name + '_se_relu1')\n",
    "        self.conv2 = Conv2D(filters, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "                               use_bias=True, name=name + '_se_conv2')\n",
    "        self.sigmoid = Activation('sigmoid', name=name + '_se_sigmoid')\n",
    "#         self.reshape = Reshape([1, 1, filters])\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.pool(inputs)\n",
    "#         x = self.se_dense1(x)\n",
    "#         x = self.se_dense2(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.sigmoid(x)\n",
    "#         x = self.reshape(x)\n",
    "        x = tf.keras.layers.multiply([x, inputs])\n",
    "        return x\n",
    "    \n",
    "\n",
    "class SEResnet(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, block_type, blocks, name='se-resnet50'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = Conv2D(64, kernel_size=3, strides=1, \n",
    "                            padding='valid', use_bias=False, name='conv1')\n",
    "        self.bn1 = BatchNormalization(name='conv1_bn')\n",
    "        self.relu1 = Activation('relu', name='conv1_relu')\n",
    "        \n",
    "        self.stage2 = self.build_stage(64, block_type, blocks[0], strides=1, stage=2)\n",
    "        self.stage3 = self.build_stage(128, block_type, blocks[1], strides=2, stage=3)\n",
    "        self.stage4 = self.build_stage(256, block_type, blocks[2], strides=2, stage=4)\n",
    "        self.stage5 = self.build_stage(512, block_type, blocks[3], strides=2, stage=5)\n",
    "\n",
    "    def build_stage(self, filters, block_type, n_blocks, strides, stage):\n",
    "        \n",
    "        downsample = tf.keras.Sequential([\n",
    "            Conv2D(filters * block_type.expansion, kernel_size=1, strides=strides, name=f'conv{stage}_0_conv0'),\n",
    "            BatchNormalization(name=f'conv{stage}_0_bn0')\n",
    "        ])\n",
    "        \n",
    "        blocks = [block_type(filters, stage, block=1, strides=strides, downsample=downsample)]\n",
    "        for i in range(1, n_blocks):\n",
    "            blocks.append(block_type(filters, stage, block=i+1, strides=1))\n",
    "            \n",
    "        return tf.keras.Sequential(blocks)\n",
    "            \n",
    "    def call(self, inputs, training=False):\n",
    "        x = ZeroPadding2D()(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.stage2(x, training=training)\n",
    "        x = self.stage3(x, training=training)\n",
    "        x = self.stage4(x, training=training)\n",
    "        x = self.stage5(x, training=training)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_resnet50 = SEResnet(BasicBlock, blocks=[3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"se_resnet_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               multiple                  1728      \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization multiple                  256       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "sequential_123 (Sequential)  multiple                  228876    \n",
      "_________________________________________________________________\n",
      "sequential_125 (Sequential)  multiple                  1127584   \n",
      "_________________________________________________________________\n",
      "sequential_127 (Sequential)  multiple                  6880096   \n",
      "_________________________________________________________________\n",
      "sequential_129 (Sequential)  multiple                  13221984  \n",
      "=================================================================\n",
      "Total params: 21,460,524\n",
      "Trainable params: 21,443,372\n",
      "Non-trainable params: 17,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "se_resnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 14, 14, 512])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = se_resnet50(inputs)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "r50 = tf.keras.applications.ResNet50(input_shape=(112, 112, 3), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 4, 4, 2048])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r50(inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 118, 118, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 56, 56, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 56, 56, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 56, 56, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 58, 58, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 28, 28, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 28, 28, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 28, 28, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 28, 28, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 28, 28, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 28, 28, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 28, 28, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 28, 28, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 28, 28, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 28, 28, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 28, 28, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 28, 28, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 28, 28, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 28, 28, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 28, 28, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 28, 28, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 28, 28, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 28, 28, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 28, 28, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 28, 28, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 14, 14, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 14, 14, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 14, 14, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 14, 14, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 14, 14, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 14, 14, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 14, 14, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 14, 14, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 14, 14, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 14, 14, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 14, 14, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 14, 14, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 14, 14, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 14, 14, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 14, 14, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 14, 14, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 14, 14, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 14, 14, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 14, 14, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 14, 14, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 14, 14, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 14, 14, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 14, 14, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 14, 14, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 14, 14, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 7, 7, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 7, 7, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 7, 7, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 7, 7, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 7, 7, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 7, 7, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 7, 7, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 7, 7, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 7, 7, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 7, 7, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 7, 7, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 7, 7, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 7, 7, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 7, 7, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 7, 7, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 7, 7, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 7, 7, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 7, 7, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 7, 7, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 7, 7, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 7, 7, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 7, 7, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 4, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 4, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 4, 4, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 4, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 4, 4, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 4, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 4, 4, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 4, 4, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "r50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 401408), dtype=float32, numpy=\n",
       "array([[0.00077106, 0.        , 0.        , ..., 0.01320089, 0.00525532,\n",
       "        0.00012029],\n",
       "       [0.00077106, 0.        , 0.        , ..., 0.01320088, 0.00525532,\n",
       "        0.00012029]], dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flatten()(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"se_resnet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               multiple                  1728      \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization multiple                  256       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "sequential_31 (Sequential)   multiple                  244272    \n",
      "_________________________________________________________________\n",
      "sequential_33 (Sequential)   multiple                  1360512   \n",
      "_________________________________________________________________\n",
      "sequential_35 (Sequential)   multiple                  7912832   \n",
      "_________________________________________________________________\n",
      "sequential_37 (Sequential)   multiple                  16568704  \n",
      "=================================================================\n",
      "Total params: 26,088,304\n",
      "Trainable params: 26,035,184\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "se_resnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = tl.layers.ReshapeLayer(net, shape=[-1, net_shape[1]*net_shape[2]*net_shape[3]], name='E_Reshapelayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 14, 14, 2048), dtype=float32, numpy=\n",
       "array([[[[2.60395766e-03, 7.80167244e-03, 0.00000000e+00, ...,\n",
       "          7.31014507e-03, 3.11156124e-04, 8.52757017e-04],\n",
       "         [4.94300108e-03, 1.35528538e-02, 0.00000000e+00, ...,\n",
       "          1.37080923e-02, 1.59830949e-03, 1.94010744e-03],\n",
       "         [6.63624052e-03, 1.71622336e-02, 0.00000000e+00, ...,\n",
       "          1.51520651e-02, 1.77050428e-03, 5.45564853e-03],\n",
       "         ...,\n",
       "         [3.68480105e-04, 1.67093473e-03, 0.00000000e+00, ...,\n",
       "          1.40380450e-02, 1.27022795e-03, 4.02054936e-03],\n",
       "         [1.45441769e-02, 1.36701884e-02, 0.00000000e+00, ...,\n",
       "          2.05905568e-02, 2.01677717e-03, 3.40851257e-04],\n",
       "         [4.45851078e-03, 3.82111734e-03, 0.00000000e+00, ...,\n",
       "          1.45491855e-02, 7.22471275e-04, 3.08329007e-03]],\n",
       "\n",
       "        [[4.30447329e-03, 1.52721554e-02, 1.55494025e-04, ...,\n",
       "          9.80110839e-03, 3.12765478e-05, 2.81450595e-03],\n",
       "         [7.53156189e-03, 2.03183684e-02, 0.00000000e+00, ...,\n",
       "          2.20601149e-02, 0.00000000e+00, 5.70101198e-03],\n",
       "         [5.07944450e-03, 1.87616646e-02, 0.00000000e+00, ...,\n",
       "          2.12589409e-02, 0.00000000e+00, 6.19731611e-03],\n",
       "         ...,\n",
       "         [9.73415561e-03, 1.63053200e-02, 0.00000000e+00, ...,\n",
       "          1.84771810e-02, 0.00000000e+00, 4.38180100e-03],\n",
       "         [9.50603839e-03, 1.15386928e-02, 0.00000000e+00, ...,\n",
       "          1.98665392e-02, 2.21069262e-04, 9.30799264e-03],\n",
       "         [5.26002049e-03, 5.25552919e-03, 0.00000000e+00, ...,\n",
       "          1.47587191e-02, 9.29139904e-04, 2.07055779e-03]],\n",
       "\n",
       "        [[5.81791252e-03, 2.00370122e-02, 6.04400237e-04, ...,\n",
       "          1.33393938e-02, 7.58277893e-04, 5.17167011e-03],\n",
       "         [6.78360835e-03, 2.16134358e-02, 0.00000000e+00, ...,\n",
       "          2.71122754e-02, 0.00000000e+00, 8.37696902e-03],\n",
       "         [9.85347759e-03, 1.84923913e-02, 0.00000000e+00, ...,\n",
       "          2.78002284e-02, 4.53471672e-04, 8.94006342e-03],\n",
       "         ...,\n",
       "         [2.50976067e-04, 6.21664990e-03, 0.00000000e+00, ...,\n",
       "          9.73406620e-03, 0.00000000e+00, 3.22310533e-03],\n",
       "         [1.13759562e-02, 1.15500176e-02, 0.00000000e+00, ...,\n",
       "          1.14461156e-02, 1.02203654e-03, 2.66154995e-03],\n",
       "         [4.02219174e-03, 3.53814266e-03, 0.00000000e+00, ...,\n",
       "          7.82976672e-03, 6.97538082e-04, 8.53084144e-04]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[8.45677033e-03, 2.42449809e-02, 1.94798724e-03, ...,\n",
       "          3.02084852e-02, 0.00000000e+00, 5.92793943e-03],\n",
       "         [1.85370203e-02, 2.81951036e-02, 0.00000000e+00, ...,\n",
       "          5.43985628e-02, 1.07211107e-03, 8.35485104e-03],\n",
       "         [1.55371726e-02, 2.90454105e-02, 0.00000000e+00, ...,\n",
       "          4.35896739e-02, 5.97246806e-04, 6.97310548e-03],\n",
       "         ...,\n",
       "         [3.09868287e-02, 2.64424961e-02, 0.00000000e+00, ...,\n",
       "          4.66349572e-02, 1.84062007e-03, 6.96668541e-03],\n",
       "         [1.69350207e-02, 2.96287946e-02, 0.00000000e+00, ...,\n",
       "          2.67034974e-02, 0.00000000e+00, 7.12606171e-03],\n",
       "         [9.79094952e-03, 1.11897858e-02, 0.00000000e+00, ...,\n",
       "          2.26231720e-02, 2.65946356e-03, 2.21373909e-03]],\n",
       "\n",
       "        [[9.67229810e-03, 2.63068527e-02, 9.52017086e-04, ...,\n",
       "          2.10511759e-02, 0.00000000e+00, 5.21538313e-03],\n",
       "         [1.71672981e-02, 2.91058794e-02, 0.00000000e+00, ...,\n",
       "          4.49575149e-02, 7.92647013e-04, 6.85632322e-03],\n",
       "         [1.51796006e-02, 2.77859494e-02, 0.00000000e+00, ...,\n",
       "          3.93048748e-02, 3.89096094e-04, 5.94797172e-03],\n",
       "         ...,\n",
       "         [9.77480412e-03, 1.69316512e-02, 3.84814484e-04, ...,\n",
       "          3.18754800e-02, 0.00000000e+00, 5.39830886e-03],\n",
       "         [1.04443934e-02, 2.53667179e-02, 0.00000000e+00, ...,\n",
       "          3.52483504e-02, 1.46046863e-04, 6.03849581e-03],\n",
       "         [1.25570064e-02, 1.53315123e-02, 0.00000000e+00, ...,\n",
       "          2.48014405e-02, 1.88502437e-03, 3.76336230e-03]],\n",
       "\n",
       "        [[1.79606136e-02, 1.94574203e-02, 2.29334622e-03, ...,\n",
       "          2.55198851e-02, 0.00000000e+00, 5.18998131e-03],\n",
       "         [1.90738570e-02, 2.53104288e-02, 2.69451004e-04, ...,\n",
       "          4.19598818e-02, 0.00000000e+00, 5.35899866e-03],\n",
       "         [1.70348063e-02, 2.55052894e-02, 5.99953870e-04, ...,\n",
       "          4.48300689e-02, 0.00000000e+00, 6.63459487e-03],\n",
       "         ...,\n",
       "         [1.31727280e-02, 2.08326280e-02, 0.00000000e+00, ...,\n",
       "          3.58315110e-02, 0.00000000e+00, 5.16972458e-03],\n",
       "         [1.39580797e-02, 2.21448820e-02, 0.00000000e+00, ...,\n",
       "          3.19815166e-02, 0.00000000e+00, 3.67070828e-03],\n",
       "         [1.24690011e-02, 1.65172499e-02, 0.00000000e+00, ...,\n",
       "          2.82518342e-02, 9.73120215e-04, 2.17721378e-03]]],\n",
       "\n",
       "\n",
       "       [[[2.60396278e-03, 7.80167384e-03, 0.00000000e+00, ...,\n",
       "          7.31014460e-03, 3.11157084e-04, 8.52761790e-04],\n",
       "         [4.94300947e-03, 1.35528548e-02, 0.00000000e+00, ...,\n",
       "          1.37080988e-02, 1.59831019e-03, 1.94010872e-03],\n",
       "         [6.63624052e-03, 1.71622429e-02, 0.00000000e+00, ...,\n",
       "          1.51520595e-02, 1.77050580e-03, 5.45565318e-03],\n",
       "         ...,\n",
       "         [3.68484179e-04, 1.67093449e-03, 0.00000000e+00, ...,\n",
       "          1.40380524e-02, 1.27022807e-03, 4.02054843e-03],\n",
       "         [1.45441741e-02, 1.36701837e-02, 0.00000000e+00, ...,\n",
       "          2.05905568e-02, 2.01677671e-03, 3.40850354e-04],\n",
       "         [4.45851171e-03, 3.82111873e-03, 0.00000000e+00, ...,\n",
       "          1.45491883e-02, 7.22471392e-04, 3.08329402e-03]],\n",
       "\n",
       "        [[4.30446770e-03, 1.52721563e-02, 1.55493879e-04, ...,\n",
       "          9.80111491e-03, 3.12773627e-05, 2.81450618e-03],\n",
       "         [7.53155863e-03, 2.03183740e-02, 0.00000000e+00, ...,\n",
       "          2.20601205e-02, 0.00000000e+00, 5.70100546e-03],\n",
       "         [5.07944822e-03, 1.87616646e-02, 0.00000000e+00, ...,\n",
       "          2.12589446e-02, 0.00000000e+00, 6.19730726e-03],\n",
       "         ...,\n",
       "         [9.73415840e-03, 1.63053237e-02, 0.00000000e+00, ...,\n",
       "          1.84771847e-02, 0.00000000e+00, 4.38179960e-03],\n",
       "         [9.50604305e-03, 1.15386974e-02, 0.00000000e+00, ...,\n",
       "          1.98665392e-02, 2.21069669e-04, 9.30799451e-03],\n",
       "         [5.26002189e-03, 5.25552686e-03, 0.00000000e+00, ...,\n",
       "          1.47587191e-02, 9.29138449e-04, 2.07055872e-03]],\n",
       "\n",
       "        [[5.81791112e-03, 2.00370159e-02, 6.04399655e-04, ...,\n",
       "          1.33393975e-02, 7.58276088e-04, 5.17166685e-03],\n",
       "         [6.78362465e-03, 2.16134451e-02, 0.00000000e+00, ...,\n",
       "          2.71122605e-02, 0.00000000e+00, 8.37696344e-03],\n",
       "         [9.85347759e-03, 1.84923876e-02, 0.00000000e+00, ...,\n",
       "          2.78002396e-02, 4.53472254e-04, 8.94007087e-03],\n",
       "         ...,\n",
       "         [2.50973972e-04, 6.21664943e-03, 0.00000000e+00, ...,\n",
       "          9.73406620e-03, 0.00000000e+00, 3.22310580e-03],\n",
       "         [1.13759572e-02, 1.15500093e-02, 0.00000000e+00, ...,\n",
       "          1.14461211e-02, 1.02203642e-03, 2.66154949e-03],\n",
       "         [4.02219500e-03, 3.53814266e-03, 0.00000000e+00, ...,\n",
       "          7.82977045e-03, 6.97539654e-04, 8.53083911e-04]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[8.45676754e-03, 2.42449809e-02, 1.94798713e-03, ...,\n",
       "          3.02085057e-02, 0.00000000e+00, 5.92794036e-03],\n",
       "         [1.85370147e-02, 2.81951092e-02, 0.00000000e+00, ...,\n",
       "          5.43985404e-02, 1.07211061e-03, 8.35485477e-03],\n",
       "         [1.55371837e-02, 2.90454011e-02, 0.00000000e+00, ...,\n",
       "          4.35896665e-02, 5.97248902e-04, 6.97310269e-03],\n",
       "         ...,\n",
       "         [3.09868492e-02, 2.64424793e-02, 0.00000000e+00, ...,\n",
       "          4.66349795e-02, 1.84061960e-03, 6.96668308e-03],\n",
       "         [1.69350374e-02, 2.96287984e-02, 0.00000000e+00, ...,\n",
       "          2.67035048e-02, 0.00000000e+00, 7.12604914e-03],\n",
       "         [9.79096070e-03, 1.11897914e-02, 0.00000000e+00, ...,\n",
       "          2.26231813e-02, 2.65946286e-03, 2.21374049e-03]],\n",
       "\n",
       "        [[9.67231579e-03, 2.63068471e-02, 9.52016679e-04, ...,\n",
       "          2.10511740e-02, 0.00000000e+00, 5.21538034e-03],\n",
       "         [1.71672888e-02, 2.91058850e-02, 0.00000000e+00, ...,\n",
       "          4.49575372e-02, 7.92650622e-04, 6.85632275e-03],\n",
       "         [1.51795959e-02, 2.77859624e-02, 0.00000000e+00, ...,\n",
       "          3.93048488e-02, 3.89095861e-04, 5.94797730e-03],\n",
       "         ...,\n",
       "         [9.77480318e-03, 1.69316512e-02, 3.84814717e-04, ...,\n",
       "          3.18754800e-02, 0.00000000e+00, 5.39830839e-03],\n",
       "         [1.04443897e-02, 2.53667105e-02, 0.00000000e+00, ...,\n",
       "          3.52483466e-02, 1.46047561e-04, 6.03849441e-03],\n",
       "         [1.25570055e-02, 1.53315086e-02, 0.00000000e+00, ...,\n",
       "          2.48014443e-02, 1.88502448e-03, 3.76336090e-03]],\n",
       "\n",
       "        [[1.79606080e-02, 1.94574278e-02, 2.29334855e-03, ...,\n",
       "          2.55198777e-02, 0.00000000e+00, 5.18998224e-03],\n",
       "         [1.90738533e-02, 2.53104549e-02, 2.69451353e-04, ...,\n",
       "          4.19598930e-02, 0.00000000e+00, 5.35899820e-03],\n",
       "         [1.70348119e-02, 2.55052745e-02, 5.99952007e-04, ...,\n",
       "          4.48300689e-02, 0.00000000e+00, 6.63458928e-03],\n",
       "         ...,\n",
       "         [1.31727345e-02, 2.08326299e-02, 0.00000000e+00, ...,\n",
       "          3.58314998e-02, 0.00000000e+00, 5.16972039e-03],\n",
       "         [1.39580835e-02, 2.21448801e-02, 0.00000000e+00, ...,\n",
       "          3.19815278e-02, 0.00000000e+00, 3.67070572e-03],\n",
       "         [1.24690030e-02, 1.65172406e-02, 0.00000000e+00, ...,\n",
       "          2.82518286e-02, 9.73120448e-04, 2.17720680e-03]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_resnet101 = SEResnet(blocks=[3, 4, 23, 3])\n",
    "se_resnet101(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"se_resnet_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               multiple                  1728      \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization multiple                  256       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "sequential_39 (Sequential)   multiple                  244272    \n",
      "_________________________________________________________________\n",
      "sequential_41 (Sequential)   multiple                  1360512   \n",
      "_________________________________________________________________\n",
      "sequential_43 (Sequential)   multiple                  29203904  \n",
      "_________________________________________________________________\n",
      "sequential_45 (Sequential)   multiple                  16568704  \n",
      "=================================================================\n",
      "Total params: 47,379,376\n",
      "Trainable params: 47,274,032\n",
      "Non-trainable params: 105,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "se_resnet101.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [64, 128, 256, 512]\n",
    "blocks = [2, 12, 29, 2]\n",
    "input_shape = (None, 112, 112, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet100 = ResNet100(filters, blocks)\n",
    "resnet100.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 7, 7, 512)\n",
      "(None, 7, 7, 512)\n",
      "(None, 7, 7, 512)\n",
      "(None, 7, 7, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 512)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = resnet100.predict(inputs)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units, version_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 64, 128, 256, 512]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [2, 12, 29, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.advanced_activations.PReLU at 0x7f4b087c0668>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Conv2D(filter_list, kernel_size=(3, 3), strides=(1, 1), padding='same', use_bias=False)\n",
    "tf.keras.layers.BatchNormalization()\n",
    "tf.keras.layers.PReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_stages):\n",
    "    body = residual_unit_v1_L(body, filter_list[i+1], (2, 2), False,\n",
    "        name='stage%d_unit%d' % (i + 1, 1), bottle_neck=bottle_neck, **kwargs)\n",
    "    \n",
    "    for j in range(units[i]-1):\n",
    "        body = residual_unit(body, filter_list[i+1], (1,1), True, name='stage%d_unit%d' % (i+1, j+2),\n",
    "          bottle_neck=bottle_neck, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_unit_v1_L(data, num_filter, stride, dim_match, name, bottle_neck, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx\n"
     ]
    }
   ],
   "source": [
    "#se begin\n",
    "          body = mx.sym.Pooling(data=bn2, global_pool=True, kernel=(7, 7), pool_type='avg', name=name+'_se_pool1')\n",
    "          body = Conv(data=body, num_filter=num_filter//16, kernel=(1,1), stride=(1,1), pad=(0,0),\n",
    "                                    name=name+\"_se_conv1\", workspace=workspace)\n",
    "          body = Act(data=body, act_type=act_type, name=name+'_se_relu1')\n",
    "          body = Conv(data=body, num_filter=num_filter, kernel=(1,1), stride=(1,1), pad=(0,0),\n",
    "                                    name=name+\"_se_conv2\", workspace=workspace)\n",
    "          body = mx.symbol.Activation(data=body, act_type='sigmoid', name=name+\"_se_sigmoid\")\n",
    "          bn2 = mx.symbol.broadcast_mul(bn2, body)\n",
    "          #se end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_unit_v1_L(name, filters, stride):\n",
    "    tf.keras.layers.ZeroPadding2D((1, 1))\n",
    "    tf.keras.layers.Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same', use_bias=False)\n",
    "    tf.keras.layers.BatchNormalization()\n",
    "    tf.keras.layers.PReLU()\n",
    "    \n",
    "    tf.keras.layers.ZeroPadding2D((1, 1))\n",
    "    tf.keras.layers.Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same', use_bias=False)\n",
    "    bn2 = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    # begin se\n",
    "    tf.keras.layers.AveragePooling2D(pool_size=(7, 7))\n",
    "    tf.keras.layers.Conv2D(filters//16, kernel_size=(1, 1), strides=(1, 1), padding='same', use_bias=False)\n",
    "    tf.keras.layers.PReLU()\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters, kernel_size=(1, 1), strides=(1, 1), padding='same', use_bias=False)\n",
    "    x = tf.keras.layers.PReLU()\n",
    "    \n",
    "    bn2 = bn2 * x\n",
    "    # end se\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters, kernel_size=(1, 1), strides=stride, padding='same', use_bias=False)\n",
    "    shortcut = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    x = bn2 + shortcut\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = Conv(data=data, num_filter=num_filter, kernel=(3,3), stride=(1,1), pad=(1,1),\n",
    "                              no_bias=True, workspace=workspace, name=name + '_conv1')\n",
    "bn1 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + '_bn1')\n",
    "act1 = Act(data=bn1, act_type=act_type, name=name + '_relu1')\n",
    "conv2 = Conv(data=act1, num_filter=num_filter, kernel=(3,3), stride=stride, pad=(1,1),\n",
    "                              no_bias=True, workspace=workspace, name=name + '_conv2')\n",
    "bn2 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + '_bn2')\n",
    "if use_se:\n",
    "  #se begin\n",
    "  body = mx.sym.Pooling(data=bn2, global_pool=True, kernel=(7, 7), pool_type='avg', name=name+'_se_pool1')\n",
    "  body = Conv(data=body, num_filter=num_filter//16, kernel=(1,1), stride=(1,1), pad=(0,0),\n",
    "                            name=name+\"_se_conv1\", workspace=workspace)\n",
    "  body = Act(data=body, act_type=act_type, name=name+'_se_relu1')\n",
    "  body = Conv(data=body, num_filter=num_filter, kernel=(1,1), stride=(1,1), pad=(0,0),\n",
    "                            name=name+\"_se_conv2\", workspace=workspace)\n",
    "  body = mx.symbol.Activation(data=body, act_type='sigmoid', name=name+\"_se_sigmoid\")\n",
    "  bn2 = mx.symbol.broadcast_mul(bn2, body)\n",
    "  #se end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_unit_v1_L(data, num_filter, stride, dim_match, name, bottle_neck, **kwargs):\n",
    "    \"\"\"Return ResNet Unit symbol for building ResNet\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : str\n",
    "        Input data\n",
    "    num_filter : int\n",
    "        Number of output channels\n",
    "    bnf : int\n",
    "        Bottle neck channels factor with regard to num_filter\n",
    "    stride : tuple\n",
    "        Stride used in convolution\n",
    "    dim_match : Boolean\n",
    "        True means channel number between input and output is the same, otherwise means differ\n",
    "    name : str\n",
    "        Base name of the operators\n",
    "    workspace : int\n",
    "        Workspace used in convolution operator\n",
    "    \"\"\"\n",
    "    use_se = kwargs.get('version_se', 1)\n",
    "    bn_mom = kwargs.get('bn_mom', 0.9)\n",
    "    workspace = kwargs.get('workspace', 256)\n",
    "    memonger = kwargs.get('memonger', False)\n",
    "    act_type = kwargs.get('version_act', 'prelu')\n",
    "    #print('in unit1')\n",
    "    if bottle_neck:\n",
    "        conv1 = Conv(data=data, num_filter=int(num_filter*0.25), kernel=(1,1), stride=(1,1), pad=(0,0),\n",
    "                                   no_bias=True, workspace=workspace, name=name + '_conv1')\n",
    "        bn1 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + '_bn1')\n",
    "        act1 = Act(data=bn1, act_type=act_type, name=name + '_relu1')\n",
    "        conv2 = Conv(data=act1, num_filter=int(num_filter*0.25), kernel=(3,3), stride=(1,1), pad=(1,1),\n",
    "                                   no_bias=True, workspace=workspace, name=name + '_conv2')\n",
    "        bn2 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + '_bn2')\n",
    "        act2 = Act(data=bn2, act_type=act_type, name=name + '_relu2')\n",
    "        conv3 = Conv(data=act2, num_filter=num_filter, kernel=(1,1), stride=stride, pad=(0,0), no_bias=True,\n",
    "                                   workspace=workspace, name=name + '_conv3')\n",
    "        bn3 = mx.sym.BatchNorm(data=conv3, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + '_bn3')\n",
    "\n",
    "        if use_se:\n",
    "          #se begin\n",
    "          body = mx.sym.Pooling(data=bn3, global_pool=True, kernel=(7, 7), pool_type='avg', name=name+'_se_pool1')\n",
    "          body = Conv(data=body, num_filter=num_filter//16, kernel=(1,1), stride=(1,1), pad=(0,0),\n",
    "                                    name=name+\"_se_conv1\", workspace=workspace)\n",
    "          body = Act(data=body, act_type=act_type, name=name+'_se_relu1')\n",
    "          body = Conv(data=body, num_filter=num_filter, kernel=(1,1), stride=(1,1), pad=(0,0),\n",
    "                                    name=name+\"_se_conv2\", workspace=workspace)\n",
    "          body = mx.symbol.Activation(data=body, act_type='sigmoid', name=name+\"_se_sigmoid\")\n",
    "          bn3 = mx.symbol.broadcast_mul(bn3, body)\n",
    "          #se end\n",
    "\n",
    "        if dim_match:\n",
    "            shortcut = data\n",
    "        else:\n",
    "            conv1sc = Conv(data=data, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n",
    "                                            workspace=workspace, name=name+'_conv1sc')\n",
    "            shortcut = mx.sym.BatchNorm(data=conv1sc, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + '_sc')\n",
    "        if memonger:\n",
    "            shortcut._set_attr(mirror_stage='True')\n",
    "        return Act(data=bn3 + shortcut, act_type=act_type, name=name + '_relu3')\n",
    "    else:\n",
    "        conv1 = Conv(data=data, num_filter=num_filter, kernel=(3,3), stride=(1,1), pad=(1,1),\n",
    "                                      no_bias=True, workspace=workspace, name=name + '_conv1')\n",
    "        bn1 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + '_bn1')\n",
    "        act1 = Act(data=bn1, act_type=act_type, name=name + '_relu1')\n",
    "        conv2 = Conv(data=act1, num_filter=num_filter, kernel=(3,3), stride=stride, pad=(1,1),\n",
    "                                      no_bias=True, workspace=workspace, name=name + '_conv2')\n",
    "        bn2 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + '_bn2')\n",
    "        if use_se:\n",
    "          #se begin\n",
    "          body = mx.sym.Pooling(data=bn2, global_pool=True, kernel=(7, 7), pool_type='avg', name=name+'_se_pool1')\n",
    "          body = Conv(data=body, num_filter=num_filter//16, kernel=(1,1), stride=(1,1), pad=(0,0),\n",
    "                                    name=name+\"_se_conv1\", workspace=workspace)\n",
    "          body = Act(data=body, act_type=act_type, name=name+'_se_relu1')\n",
    "          body = Conv(data=body, num_filter=num_filter, kernel=(1,1), stride=(1,1), pad=(0,0),\n",
    "                                    name=name+\"_se_conv2\", workspace=workspace)\n",
    "          body = mx.symbol.Activation(data=body, act_type='sigmoid', name=name+\"_se_sigmoid\")\n",
    "          bn2 = mx.symbol.broadcast_mul(bn2, body)\n",
    "          #se end\n",
    "\n",
    "        if dim_match:\n",
    "            shortcut = data\n",
    "        else:\n",
    "            conv1sc = Conv(data=data, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n",
    "                                            workspace=workspace, name=name+'_conv1sc')\n",
    "            shortcut = mx.sym.BatchNorm(data=conv1sc, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + '_sc')\n",
    "        if memonger:\n",
    "            shortcut._set_attr(mirror_stage='True')\n",
    "        return Act(data=bn2 + shortcut, act_type=act_type, name=name + '_relu3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = Conv(data=body, num_filter=filter_list[0], kernel=(3,3), stride=(1,1), pad=(1, 1),\n",
    "                                no_bias=True, name=\"conv0\", workspace=workspace)\n",
    "      body = mx.sym.BatchNorm(data=body, fix_gamma=False, eps=2e-5, momentum=bn_mom, name='bn0')\n",
    "      body = Act(data=body, act_type=act_type, name='relu0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ar-models",
   "language": "python",
   "name": "ar-models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
